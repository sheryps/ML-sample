{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "mask_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "15H6gS4Ip4DxxzNTExUfHEfpgXKAxeheQ",
      "authorship_tag": "ABX9TyP+jsKtk0PkW/Gz156vGz/m",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sheryps/calculations/blob/main/mask_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bDRlu1nI8TIP"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Z24BFXigyL0w"
      },
      "source": [
        "class LeNet:\n",
        "\n",
        "\tdef build(width, height, depth, classes):\n",
        "\t\t# initialize the model\n",
        "\t\tmodel = Sequential()\n",
        "\t\tinputShape = (height, width, depth)\n",
        "\n",
        "\t\t# if we are using \"channels first\", update the input shape\n",
        "\t\tif K.image_data_format() == \"channels_first\":\n",
        "\t\t\tinputShape = (depth, height, width)\n",
        "\n",
        "\t\t# first set of CONV => RELU => POOL layers\n",
        "\t\tmodel.add(Conv2D(20, (5, 5), padding=\"same\",\n",
        "\t\t\tinput_shape=inputShape))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "\t\t# second set of CONV => RELU => POOL layers\n",
        "\t\tmodel.add(Conv2D(50, (5, 5), padding=\"same\"))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "\t\t# first (and only) set of FC => RELU layers\n",
        "\t\tmodel.add(Flatten())\n",
        "\t\tmodel.add(Dense(500))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\n",
        "\t\t# softmax classifier\n",
        "\t\tmodel.add(Dense(classes))\n",
        "\t\tmodel.add(Activation(\"softmax\"))\n",
        "\n",
        "\t\t# return the constructed network architecture\n",
        "\t\treturn model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oyd_a28Ox9H0"
      },
      "source": [
        "# set the matplotlib backend so figures can be saved in the background\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "\n",
        "# import the necessary packages\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "#from lenet import LeNet\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import random\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "A6AphmZ9yTvu"
      },
      "source": [
        "# construct the argument parse and parse the arguments\n",
        "#ap = argparse.ArgumentParser()\n",
        "#ap.add_argument(\"-d\", \"--dataset\", required=True,help=\"path to input dataset\")\n",
        "#ap.add_argument(\"-m\", \"--model\", required=True,help=\"path to output model\")\n",
        "#ap.add_argument(\"-p\", \"--plot\", type=str, default=\"plot.png\",help=\"path to output loss/accuracy plot\")\n",
        "#args = vars(ap.parse_args())\n",
        "\n",
        "# initialize the number of epochs to train for, initia learning rate,\n",
        "# and batch size\n",
        "EPOCHS = 15\n",
        "INIT_LR = 1e-2\n",
        "BS = 32\n",
        "\n",
        "# initialize the data and labels\n",
        "print(\"[INFO] loading images...\")\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "# grab the image paths and randomly shuffle them\n",
        "imagePaths = sorted(list(paths.list_images('/content/drive/MyDrive/DEEP LEARNING/MASK DETECTION/mask data')))\n",
        "print(len(imagePaths))\n",
        "random.seed(42)\n",
        "random.shuffle(imagePaths)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kX-r4tlOydqD",
        "outputId": "7a98973f-a9ce-4870-8460-860775a821aa"
      },
      "source": [
        "# loop over the input images\n",
        "for imagePath in imagePaths:\n",
        "  image = cv2.imread(imagePath)\n",
        "  image = cv2.resize(image, (28, 28))\n",
        "  image = img_to_array(image)\n",
        "  data.append(image)\n",
        "  label = imagePath.split(os.path.sep)[-2]\n",
        "  if label==\"0\":\n",
        "    label= 0\n",
        "        \n",
        "  elif label==\"1\":\n",
        "\t  label= 1\n",
        "        \n",
        "  elif label==\"2\":\n",
        "\t  label=2\n",
        "\t\n",
        "\n",
        "#  # elif label==\"3\":\n",
        "# #\t  label=3\n",
        "        \n",
        "# #  elif label==\"4\":\n",
        "# #\t  label=4\n",
        "        \n",
        "\t\n",
        "# #  elif label==\"5\":\n",
        "# #\t  label=5\n",
        "        \n",
        "# #   elif label==\"6\":\n",
        "# # \t  label= 6\n",
        "        \n",
        "# #   elif label==\"7\":\n",
        "# # \t  label= 7\n",
        "        \n",
        "# #   elif label==\"8\":\n",
        "# # \t  label= 8\n",
        "        \n",
        "# #   else\n",
        "# # \t  label= 9 \n",
        "  labels.append(label)\n",
        "# ############################"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "IndentationError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-de06c1fda863>\"\u001b[0;36m, line \u001b[0;32m21\u001b[0m\n\u001b[0;31m    elif label==\"4\":\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IweBNT2iyiY-",
        "outputId": "52bde2ac-ba24-4759-b5b0-f7dbc2661a83"
      },
      "source": [
        "# scale the raw pixel intensities to the range [0, 1]\n",
        "data = np.array(data, dtype=\"float\") / 255.0\n",
        "labels = np.array(label)\n",
        "\n",
        "\n",
        "# # partition the data into training and testing splits using 75% of\n",
        "# # the data for training and the remaining 25% for testing\n",
        "(trainX, testX, trainY, testY) = train_test_split(data,labels, test_size=0.35 ,random_state=42)\n",
        "\n",
        "# # convert the labels from integers to vectors\n",
        "trainY = to_categorical(trainY, num_classes=2)\n",
        "testY = to_categorical(testY, num_classes=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-f391b15b0641>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# # partition the data into training and testing splits using 75% of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# # the data for training and the remaining 25% for testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.35\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# # convert the labels from integers to vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2116\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid parameters passed: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2118\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2120\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \"\"\"\n\u001b[1;32m    247\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \"\"\"\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \"\"\"\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             raise TypeError(\"Singleton array %r cannot be considered\"\n\u001b[0;32m--> 152\u001b[0;31m                             \" a valid collection.\" % x)\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;31m# Check that shape is returning an integer or default to len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;31m# Dask dataframes may not return numeric shape[0] value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Singleton array array(0) cannot be considered a valid collection."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sfAxGTx0ym40"
      },
      "source": [
        "# construct the image generator for data augmentation\n",
        "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n",
        "\theight_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
        "\thorizontal_flip=True, fill_mode=\"nearest\")\n",
        "\n",
        "# initialize the model\n",
        "print(\"[INFO] compiling model...\")\n",
        "model = LeNet.build(width=28, height=28, depth=3, classes=6)\n",
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "u_QiB44YyrCs"
      },
      "source": [
        "# train the network\n",
        "print(\"[INFO] training network...\")\n",
        "H = model.fit_generator(aug.flow(trainX, trainY, batch_size=BS),\n",
        "\tvalidation_data=(testX, testY), steps_per_epoch=len(trainX) // BS,\n",
        "\tepochs=EPOCHS, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fSxc0XcDyuIo"
      },
      "source": [
        "# save the model to disk\n",
        "print(\"[INFO] serializing network...\")\n",
        "model.save('/content/drive/MyDrive/DEEP LEARNING/OBJECT DETECTION/realtime1.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}